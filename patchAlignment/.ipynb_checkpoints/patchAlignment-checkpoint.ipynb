{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a45db6-9206-40c2-b866-8c039b94995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import interpolate\n",
    "from basicsr.archs.spynet_arch import SpyNet\n",
    "from basicsr.utils.registry import ARCH_REGISTRY\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def load_spynet(weight_path):\n",
    "    print(\"Loading SPyNet model...\")\n",
    "    spynet = ARCH_REGISTRY.get('SpyNet')()\n",
    "    checkpoint = torch.load(weight_path, map_location='cpu')\n",
    "    spynet.load_state_dict(checkpoint['params'])\n",
    "    spynet.eval()\n",
    "    print(\"SPyNet model loaded successfully.\")\n",
    "    return spynet\n",
    "\n",
    "def divide_into_patches(image, patch_size=32):\n",
    "    h, w, _ = image.shape\n",
    "    patches = []\n",
    "    for i in range(0, h, patch_size):\n",
    "        for j in range(0, w, patch_size):\n",
    "            patch = image[i:i+patch_size, j:j+patch_size]\n",
    "            patches.append(patch)\n",
    "    print(f\"Divided image into {len(patches)} patches.\")\n",
    "    return patches\n",
    "\n",
    "def align_patches(patches, flow, patch_size=32):\n",
    "    h, w, _ = flow.shape\n",
    "    aligned_patches = []\n",
    "    for i, patch in enumerate(patches):\n",
    "        y, x = (i // (w // patch_size)) * patch_size, (i % (w // patch_size)) * patch_size\n",
    "        flow_patch = flow[y:y+patch_size, x:x+patch_size]\n",
    "        aligned_patch = warp_patch(patch, flow_patch)\n",
    "        aligned_patches.append(aligned_patch)\n",
    "    print(f\"Aligned {len(aligned_patches)} patches.\")\n",
    "    return aligned_patches\n",
    "\n",
    "def reconstruct_image(patches, image_shape):\n",
    "    h, w, _ = image_shape\n",
    "    patch_size = patches[0].shape[0]\n",
    "    reconstructed = np.zeros(image_shape, dtype=np.float32)\n",
    "    for i, patch in enumerate(patches):\n",
    "        y, x = (i // (w // patch_size)) * patch_size, (i % (w // patch_size)) * patch_size\n",
    "        reconstructed[y:y+patch_size, x:x+patch_size] = patch\n",
    "    print(\"Reconstructed image from aligned patches.\")\n",
    "    return reconstructed\n",
    "\n",
    "def warp_image(image, flow):\n",
    "    h, w = flow.shape[:2]\n",
    "    flow_map = np.column_stack((flow[..., 1].ravel(), flow[..., 0].ravel()))\n",
    "    destination = np.array(list(np.ndindex(h, w))).reshape(h, w, 2)\n",
    "    source = (destination + flow_map.reshape(h, w, 2)).reshape(-1, 2)\n",
    "    \n",
    "    warped = np.zeros_like(image)\n",
    "    for c in range(3):  # For each color channel\n",
    "        warped[..., c] = interpolate.griddata(source, image[..., c].ravel(), destination, method='linear', fill_value=0)\n",
    "    \n",
    "    print(\"Warped image based on optical flow.\")\n",
    "    return warped\n",
    "\n",
    "def warp_patch(patch, flow_patch):\n",
    "    return warp_image(patch, flow_patch)\n",
    "\n",
    "def visualize_patches(image, patch_size=32):\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    h, w, _ = image.shape\n",
    "    for i in range(0, h, patch_size):\n",
    "        for j in range(0, w, patch_size):\n",
    "            rect = patches.Rectangle((j, i), patch_size, patch_size, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "    plt.title('Image with Patch Grid')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_optical_flow(flow):\n",
    "    # Compute magnitude and angle\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    \n",
    "    # Normalize magnitude for better visualization\n",
    "    mag_normalized = cv2.normalize(mag, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Create HSV image\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2  # Hue is direction\n",
    "    hsv[..., 1] = 255  # Full saturation\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)  # Value is magnitude\n",
    "    \n",
    "    # Convert to BGR\n",
    "    flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(131), plt.imshow(flow[..., 0]), plt.title('Flow X'), plt.colorbar()\n",
    "    plt.subplot(132), plt.imshow(flow[..., 1]), plt.title('Flow Y'), plt.colorbar()\n",
    "    plt.subplot(133), plt.imshow(flow_rgb), plt.title('Flow (Color-coded)')\n",
    "    plt.show()\n",
    "\n",
    "def patch_alignment(image_burst, spynet, device='cuda'):\n",
    "    aligned_images = []\n",
    "    reference_image = image_burst[len(image_burst) // 2]  # Use middle image as reference\n",
    "    print(f\"Using image {len(image_burst) // 2} as reference.\")\n",
    "    \n",
    "    # Visualize patches on reference image\n",
    "    visualize_patches(reference_image)\n",
    "    \n",
    "    for i, image in enumerate(image_burst):\n",
    "        print(f\"\\nProcessing image {i+1}/{len(image_burst)}\")\n",
    "        \n",
    "        # Convert images to PyTorch tensors and move to device\n",
    "        ref_tensor = torch.from_numpy(reference_image).permute(2, 0, 1).float().unsqueeze(0).to(device)\n",
    "        img_tensor = torch.from_numpy(image).permute(2, 0, 1).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        # Calculate optical flow using SPyNet\n",
    "        print(\"Calculating optical flow...\")\n",
    "        with torch.no_grad():\n",
    "            flow = spynet(ref_tensor, img_tensor)\n",
    "        \n",
    "        # Convert flow back to numpy for further processing\n",
    "        flow_np = flow.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "        # Visualize optical flow\n",
    "        visualize_optical_flow(flow_np)\n",
    "        \n",
    "        # Divide image into patches\n",
    "        patches = divide_into_patches(image)\n",
    "        \n",
    "        # Align patches based on optical flow\n",
    "        aligned_patches = align_patches(patches, flow_np)\n",
    "        \n",
    "        # Reconstruct aligned image from patches\n",
    "        aligned_image = reconstruct_image(aligned_patches, image.shape)\n",
    "        \n",
    "        # Warp the aligned image\n",
    "        warped_image = warp_image(aligned_image, flow_np)\n",
    "        \n",
    "        aligned_images.append(warped_image)\n",
    "        \n",
    "        # Display intermediate results\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(231), plt.imshow(image), plt.title('Original Image')\n",
    "        plt.subplot(232), plt.imshow(aligned_image), plt.title('Aligned Image (Before Warping)')\n",
    "        plt.subplot(233), plt.imshow(warped_image), plt.title('Warped Image')\n",
    "        \n",
    "        # Display some sample patches\n",
    "        num_patches = min(3, len(patches))\n",
    "        for j in range(num_patches):\n",
    "            plt.subplot(2, 3, 4 + j)\n",
    "            plt.imshow(patches[j])\n",
    "            plt.title(f'Sample Patch {j+1}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return aligned_images\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load SPyNet model\n",
    "    spynet = load_spynet('C:\\Users\\Arnav\\Desktop\\Image SuperResolution\\patchAlignment\\spynetWeights.pth')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    spynet = spynet.to(device)\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load your burst of images\n",
    "    burst_directory = 'path/to/your/burst/images/'\n",
    "    image_burst = []\n",
    "    \n",
    "    print(\"Loading burst images...\")\n",
    "    for i in range(14):  # Adjust the range if you have a different number of images\n",
    "        image_path = os.path.join(burst_directory, f'burst_{i}.jpg')\n",
    "        if os.path.exists(image_path):\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is not None:\n",
    "                image_burst.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            print(f\"Warning: Image {image_path} not found.\")\n",
    "    \n",
    "    print(f\"Loaded {len(image_burst)} images.\")\n",
    "    \n",
    "    # Perform patch alignment\n",
    "    aligned_images = patch_alignment(image_burst, spynet, device)\n",
    "\n",
    "    # Save only the final aligned image\n",
    "    final_aligned_image = aligned_images[-1]\n",
    "    final_aligned_image_bgr = cv2.cvtColor(final_aligned_image.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite('final_aligned_image.jpg', final_aligned_image_bgr)\n",
    "    print(\"Final aligned image saved as 'final_aligned_image.jpg'.\")\n",
    "\n",
    "    # Display final result\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(121), plt.imshow(image_burst[0]), plt.title('First Image in Burst')\n",
    "    plt.subplot(122), plt.imshow(final_aligned_image), plt.title('Final Aligned Image')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Patch alignment completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1743cc-714d-469e-a8c4-960a87aed3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SyntheticBurstVal(torch.utils.data.Dataset):\n",
    "    \"\"\" Synthetic burst validation set. The validation burst have been generated using the same synthetic pipeline as\n",
    "    employed in SyntheticBurst dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.burst_list = list(range(500))\n",
    "        self.burst_size = 14\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.burst_list)\n",
    "\n",
    "    def _read_burst_image(self, index, image_id):\n",
    "        im = cv2.imread('{}/{:04d}/im_raw_{:02d}.png'.format(self.root, index, image_id), cv2.IMREAD_UNCHANGED)\n",
    "        im_t = torch.from_numpy(im.astype(np.float32)).permute(2, 0, 1).float() / (2**14)\n",
    "        return im_t\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Generates a synthetic burst\n",
    "                args:\n",
    "                    index: Index of the burst\n",
    "\n",
    "                returns:\n",
    "                    burst: LR RAW burst, a torch tensor of shape\n",
    "                           [14, 4, 48, 48]\n",
    "                           The 4 channels correspond to 'R', 'G', 'G', and 'B' values in the RGGB bayer mosaick.\n",
    "                    seq_name: Name of the burst sequence\n",
    "                \"\"\"\n",
    "        burst_name = '{:04d}'.format(index)\n",
    "        burst = [self._read_burst_image(index, i) for i in range(self.burst_size)]\n",
    "        burst = torch.stack(burst, 0)\n",
    "\n",
    "        return burst, burst_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
